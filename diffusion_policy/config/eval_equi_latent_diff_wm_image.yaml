defaults:
  - _self_
  - task: pusht_image_world_model_test

name: eval_equivariant_latent_unet_1_depth
_target_: diffusion_policy.workspace.eval_equi_diff_wm_image_workspace.EvalEquiDiffusionWorldModelUnetImageWorkspace

task_name: ${task.name}
shape_meta: ${task.shape_meta}
exp_name: "default"

n_obs_steps: 4
n_future_steps: 5
horizon: ${eval:'${n_obs_steps}+${n_future_steps}'}
dataset_obs_steps: ${n_obs_steps}
obs_as_global_cond: True


world_model:
  _target_: diffusion_policy.world_model.equivariant_latent_diffusion_world_model_unet_image.DiffusionWorldModelImageLatentEquiUnet

  shape_meta: ${shape_meta}
  
  noise_scheduler:
    _target_: diffusers.schedulers.scheduling_ddpm.DDPMScheduler
    num_train_timesteps: 10
    beta_start: 0.0001
    beta_end: 0.02
    beta_schedule: squaredcos_cap_v2
    variance_type: fixed_small # Yilun's paper uses fixed_small_log instead, but easy to cause Nan
    clip_sample: False # required when predict_epsilon=False
    prediction_type: sample # or sample

  auto_encoder:
    _target_: diffusion_policy.model.equi.equi_obs_autoencoder.EquivariantAutoencoder
    obs_channels: 3
    lats_channels: 1
    NUM_CHANNEL_1: 32
    NUM_CHANNEL_2: 64
    N: 4
    l2_loss_weight: 0
    recursive_steps: 1
    recursive_weight: 0.5
    latent_noise_std: 0.01
    latent_norm_regularization_r: 1.0
    latent_norm_regularization_weight: 0.005
  pretrained_auto_encoder_path: ./data/outputs/EquivariantAutoencoder_trvial/${world_model.auto_encoder.lats_channels}_${world_model.auto_encoder.NUM_CHANNEL_1}_${world_model.auto_encoder.NUM_CHANNEL_2}_add_noise/checkpoints/latest.ckpt

  n_obs_steps: ${n_obs_steps}
  n_future_steps: ${n_future_steps}
  num_inference_steps: 10
  obs_as_global_cond: ${obs_as_global_cond}
  # crop_shape: null
  cond_channels: 128
  depths: [2, 2, 2]
  channels: [32, 32, 32]
  attn_depths: [0,0]
  l1_loss_weight: 0.0
  cond_latent_noise_std: 0.001
  action_embedding_channels: [4, 4, 4]
  N: 4
pretrained_world_model_path: ./data/outputs/latent_unet_image/latent_autoregressive_all_equi_latent_unet/checkpoints/latest.ckpt

eval:
  device: "cuda:0"
  seed: 42
  record_video: True
  num_rollouts: 20
  calculate_ssim: False
  auto_regressive: False
  teacher_forcing_depth: 1
  test_rotate: True
  rot90: 1

hydra:
  job:
    override_dirname: ${name}
  run:
    dir: data/eval_outputs/unet_image/${name}
  sweep:
    dir: data/eval_outputs/unet_image/${name}
    subdir: ${hydra.job.num}
